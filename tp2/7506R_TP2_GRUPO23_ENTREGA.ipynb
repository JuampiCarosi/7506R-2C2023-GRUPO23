{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 2 - Procesamiento del Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score,  recall_score, precision_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import LSTM, Embedding\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review_es</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Uno de los otros críticos ha mencionado que de...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Una pequeña pequeña producción.La técnica de f...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Pensé que esta era una manera maravillosa de p...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Básicamente, hay una familia donde un niño peq...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>El \"amor en el tiempo\" de Petter Mattei es una...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Probablemente mi película favorita de todos lo...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Seguro que me gustaría ver una resurrección de...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Este espectáculo fue una idea increíble, fresc...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Alentados por los comentarios positivos sobre ...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Si te gusta la risa original desgarradora, te ...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          review_es sentimiento\n",
       "0   0  Uno de los otros críticos ha mencionado que de...    positivo\n",
       "1   1  Una pequeña pequeña producción.La técnica de f...    positivo\n",
       "2   2  Pensé que esta era una manera maravillosa de p...    positivo\n",
       "3   3  Básicamente, hay una familia donde un niño peq...    negativo\n",
       "4   4  El \"amor en el tiempo\" de Petter Mattei es una...    positivo\n",
       "5   5  Probablemente mi película favorita de todos lo...    positivo\n",
       "6   6  Seguro que me gustaría ver una resurrección de...    positivo\n",
       "7   7  Este espectáculo fue una idea increíble, fresc...    negativo\n",
       "8   8  Alentados por los comentarios positivos sobre ...    negativo\n",
       "9   9  Si te gusta la risa original desgarradora, te ...    positivo"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv', sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review_es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60000</td>\n",
       "      <td>La mayor virtud de esta película es su existen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60001</td>\n",
       "      <td>No soy un experto cinéfilo, pero pocas veces m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60002</td>\n",
       "      <td>Si no eres un incondicional del humor estilo T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60003</td>\n",
       "      <td>No sé qué está pasando, si la gente se deja ll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60004</td>\n",
       "      <td>Pero cuando amanece,y me quedo solo,siento en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8594</th>\n",
       "      <td>68594</td>\n",
       "      <td>Buena no, lo siguiente. Por fin un film serio ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8595</th>\n",
       "      <td>68595</td>\n",
       "      <td>Me esperaba mucho, pero que mucho, más.Guión m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8596</th>\n",
       "      <td>68596</td>\n",
       "      <td>De mal cuerpo como sensación al finalizar, de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8597</th>\n",
       "      <td>68597</td>\n",
       "      <td>Los que han añadido comentarios os lo han dich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8598</th>\n",
       "      <td>68598</td>\n",
       "      <td>Fui a ver esta película de cine con entusiasmo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                          review_es\n",
       "0     60000  La mayor virtud de esta película es su existen...\n",
       "1     60001  No soy un experto cinéfilo, pero pocas veces m...\n",
       "2     60002  Si no eres un incondicional del humor estilo T...\n",
       "3     60003  No sé qué está pasando, si la gente se deja ll...\n",
       "4     60004  Pero cuando amanece,y me quedo solo,siento en ...\n",
       "...     ...                                                ...\n",
       "8594  68594  Buena no, lo siguiente. Por fin un film serio ...\n",
       "8595  68595  Me esperaba mucho, pero que mucho, más.Guión m...\n",
       "8596  68596  De mal cuerpo como sensación al finalizar, de ...\n",
       "8597  68597  Los que han añadido comentarios os lo han dich...\n",
       "8598  68598  Fui a ver esta película de cine con entusiasmo...\n",
       "\n",
       "[8599 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv', sep=',')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_scores(y_test: np.ndarray, y_prediccion: np.ndarray):\n",
    "    accuracy = accuracy_score(y_test,y_prediccion)\n",
    "    recall = recall_score(y_test,y_prediccion)\n",
    "    f1 = f1_score(y_test,y_prediccion,)\n",
    "    precision = precision_score(y_test,y_prediccion)\n",
    "\n",
    "    print(\"Accuracy: \"+str(accuracy))\n",
    "    print(\"Recall: \"+str(recall))\n",
    "    print(\"Precision: \"+str(precision))\n",
    "    print(\"f1 score: \"+str(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cantidad_de_palabras(review):\n",
    "    return len(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copia = df.copy()\n",
    "df_copia['cantidad_de_palabras'] = df_copia['review_es'].apply(cantidad_de_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean       237.233680\n",
       "std        179.529306\n",
       "min          6.000000\n",
       "25%        123.000000\n",
       "50%        172.000000\n",
       "75%        293.000000\n",
       "max       2450.000000\n",
       "Name: cantidad_de_palabras, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copia['cantidad_de_palabras'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copia['review_es'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49599, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['review_es'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de palabras unicas en el dataset pre preprocesamiento: 175853\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df['review_es'])\n",
    "\n",
    "vocabulario = vectorizer.get_feature_names_out()\n",
    "\n",
    "numero_de_palabras_unicas = len(vocabulario)\n",
    "\n",
    "print(\"Numero de palabras unicas en el dataset pre preprocesamiento:\", numero_de_palabras_unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocesado = df.copy()\n",
    "#si ya estan descargados los paquetes no es necesario volver a hacerlo.\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Zñáéíóúü\\s]', '', text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    stemmer = nltk.stem.SnowballStemmer('spanish')\n",
    "    stems = [stemmer.stem(token) for token in tokens]\n",
    "    preprocessed_text = ' '.join(stems)\n",
    "    return preprocessed_text\n",
    "\n",
    "df_preprocesado['review_es'] = df_preprocesado['review_es'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review_es</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>critic mencion despues ver sol oz episodi enga...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pequeñ pequeñ produccionl tecnic filmacion inc...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pens maner maravill pas tiemp fin seman veran ...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>basic famili niñ pequeñ jak piens zombi armari...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>amor tiemp pett mattei pelicul visual impresio...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>probabl pelicul favorit tiemp histori desinter...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>segur gust ver resurreccion seri seahunt dat t...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>espectacul ide increibl fresc innov años emit ...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>alent comentari posit pelicul aqu des ver peli...</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>si gust ris original desgarr gust peliculasi j...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                          review_es sentimiento\n",
       "0   0  critic mencion despues ver sol oz episodi enga...    positivo\n",
       "1   1  pequeñ pequeñ produccionl tecnic filmacion inc...    positivo\n",
       "2   2  pens maner maravill pas tiemp fin seman veran ...    positivo\n",
       "3   3  basic famili niñ pequeñ jak piens zombi armari...    negativo\n",
       "4   4  amor tiemp pett mattei pelicul visual impresio...    positivo\n",
       "5   5  probabl pelicul favorit tiemp histori desinter...    positivo\n",
       "6   6  segur gust ver resurreccion seri seahunt dat t...    positivo\n",
       "7   7  espectacul ide increibl fresc innov años emit ...    negativo\n",
       "8   8  alent comentari posit pelicul aqu des ver peli...    negativo\n",
       "9   9  si gust ris original desgarr gust peliculasi j...    positivo"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocesado.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de palabras unicas en el dataset post preprocesamiento: 210315\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df_preprocesado['review_es'])\n",
    "\n",
    "vocabulario = vectorizer.get_feature_names_out()\n",
    "\n",
    "numero_de_palabras_unicas = len(vocabulario)\n",
    "\n",
    "print(\"Numero de palabras unicas en el dataset post preprocesamiento:\", numero_de_palabras_unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                          df['review_es'], df['sentimiento'], \n",
    "                                          test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de Bayes Naïve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vamos a probar en primer lugar con un count vectorizer y luego con un tfidf vectorizer par ver con cual obtenemos merjores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_count = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "modelo_tfidf = Pipeline([('tvec', TfidfVectorizer()), ('mnb',MultinomialNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_count.fit(x_train, y_train)\n",
    "\n",
    "prediccion = modelo_count.predict(x_test)\n",
    "\n",
    "# mostrar_scores(y_test, prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_tfidf.fit(x_train, y_train)\n",
    "\n",
    "prediccion = modelo_tfidf.predict(x_test)\n",
    "\n",
    "# mostrar_scores(y_test, prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8244623655913978\n",
      "Recall: 0.8371905274488698\n",
      "Precision: 0.8161070304302204\n",
      "f1 score: 0.8265143464399575\n"
     ]
    }
   ],
   "source": [
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocesado_copy['review_es'], df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=9000)\n",
    "modelo_tfidf = make_pipeline(vectorizer, MultinomialNB(alpha=0.5))\n",
    "modelo_tfidf.fit(X_train, y_train)\n",
    "\n",
    "prediccion = modelo_tfidf.predict(X_test)\n",
    "\n",
    "mostrar_scores(y_test, prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8508597597857082\n",
      "Recall: 0.8575684656812192\n",
      "Precision: 0.8475651189127973\n",
      "f1 score: 0.8525374494503617\n"
     ]
    }
   ],
   "source": [
    "prediccion_train = modelo_tfidf.predict(X_train)\n",
    "\n",
    "mostrar_scores(y_train, prediccion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7362231182795699\n",
      "Recall: 0.6990043057050592\n",
      "Precision: 0.7547580996658434\n",
      "f1 score: 0.7258120852252882\n"
     ]
    }
   ],
   "source": [
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocesado_copy['review_es'], df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=7000)\n",
    "modelo_gauss = make_pipeline(vectorizer,   DenseTransformer() ,GaussianNB())\n",
    "modelo_gauss.fit(X_train, y_train)\n",
    "\n",
    "prediccion = modelo_gauss.predict(X_test)\n",
    "\n",
    "mostrar_scores(y_test, prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8185714285714286\n",
      "Recall: 0.8056401125725117\n",
      "Precision: 0.8254575413405519\n",
      "f1 score: 0.8154284385536564\n"
     ]
    }
   ],
   "source": [
    "prediccion_train = modelo_gauss.predict(X_train)\n",
    "\n",
    "mostrar_scores(y_train, prediccion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8344086021505376\n",
      "Recall: 0.8223896663078579\n",
      "Precision: 0.8423373759647188\n",
      "f1 score: 0.8322440087145969\n"
     ]
    }
   ],
   "source": [
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocesado_copy['review_es'], df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=14700)\n",
    "modelo_bernoulli = make_pipeline(vectorizer, BernoulliNB(\n",
    "))\n",
    "modelo_bernoulli.fit(X_train, y_train)\n",
    "\n",
    "prediccion = modelo_bernoulli.predict(X_test)\n",
    "\n",
    "mostrar_scores(y_test, prediccion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.854056856476281\n",
      "Recall: 0.8377449295290478\n",
      "Precision: 0.8674141306282257\n",
      "f1 score: 0.8523214129579435\n"
     ]
    }
   ],
   "source": [
    "prediccion_train = modelo_bernoulli.predict(X_train)\n",
    "\n",
    "mostrar_scores(y_train, prediccion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv', sep=',')\n",
    "df_test_procesado = df_test.copy()\n",
    "\n",
    "prediccion = modelo_tfidf.predict(df_test_procesado['review_es'].apply(preprocess_text))\n",
    "prediccion = np.where(prediccion == 0, 'negativo', 'positivo')\n",
    "\n",
    "df_entrega = df_test.copy()\n",
    "\n",
    "\n",
    "df_entrega['sentimiento'] = prediccion\n",
    "df_entrega.drop('review_es', axis=1, inplace=True)\n",
    "\n",
    "df_entrega.to_csv('entrega.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8539650537634409\n",
      "Recall: 0.8867061356297093\n",
      "Precision: 0.8319656609014013\n",
      "f1 score: 0.8584641438155409\n"
     ]
    }
   ],
   "source": [
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocesado_copy['review_es'], df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "modelo_regresion_logistica = Pipeline([('tfidf', TfidfVectorizer(max_features=15000)), ('lr', LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.1,\n",
    "    solver='lbfgs',\n",
    "    max_iter=200, \n",
    "    l1_ratio=None, \n",
    "    tol=1e-4 \n",
    "))])\n",
    "modelo_regresion_logistica.fit(X_train, y_train)\n",
    "\n",
    "prediccion = modelo_regresion_logistica.predict(X_test)\n",
    "\n",
    "mostrar_scores(y_test, prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8642530026786486\n",
      "Recall: 0.8935487567319812\n",
      "Precision: 0.8452658392499052\n",
      "f1 score: 0.8687369447152207\n"
     ]
    }
   ],
   "source": [
    "prediccion_train = modelo_regresion_logistica.predict(X_train)\n",
    "\n",
    "mostrar_scores(y_train, prediccion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv', sep=',')\n",
    "df_test_copia = df_test.copy()\n",
    "df_test_copia['review_es'] = df_test_copia['review_es'].apply(preprocess_text)\n",
    "\n",
    "prediccion = modelo_regresion_logistica.predict(df_test_copia['review_es'])\n",
    "prediccion = np.where(prediccion == 0, 'negativo', 'positivo')\n",
    "\n",
    "df_entrega = df_test.copy()\n",
    "\n",
    "df_entrega['sentimiento'] = prediccion\n",
    "df_entrega.drop('review_es', axis=1, inplace=True)\n",
    "\n",
    "df_entrega.to_csv('lr_upgrade.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/juampi/Documents/uba/Cuarto Cuatrimestre/Organizacion de Datos/tp2/7506R_TP2_GRUPO23_ENTREGA.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juampi/Documents/uba/Cuarto%20Cuatrimestre/Organizacion%20de%20Datos/tp2/7506R_TP2_GRUPO23_ENTREGA.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, df_preprocesado_copy[\u001b[39m'\u001b[39m\u001b[39msentimiento\u001b[39m\u001b[39m'\u001b[39m], test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juampi/Documents/uba/Cuarto%20Cuatrimestre/Organizacion%20de%20Datos/tp2/7506R_TP2_GRUPO23_ENTREGA.ipynb#X51sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m modelo_xg_boost \u001b[39m=\u001b[39m XGBClassifier(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juampi/Documents/uba/Cuarto%20Cuatrimestre/Organizacion%20de%20Datos/tp2/7506R_TP2_GRUPO23_ENTREGA.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# learning_rate=0.001,\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juampi/Documents/uba/Cuarto%20Cuatrimestre/Organizacion%20de%20Datos/tp2/7506R_TP2_GRUPO23_ENTREGA.ipynb#X51sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     n_estimators\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juampi/Documents/uba/Cuarto%20Cuatrimestre/Organizacion%20de%20Datos/tp2/7506R_TP2_GRUPO23_ENTREGA.ipynb#X51sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juampi/Documents/uba/Cuarto%20Cuatrimestre/Organizacion%20de%20Datos/tp2/7506R_TP2_GRUPO23_ENTREGA.ipynb#X51sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/juampi/Documents/uba/Cuarto%20Cuatrimestre/Organizacion%20de%20Datos/tp2/7506R_TP2_GRUPO23_ENTREGA.ipynb#X51sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m modelo_xg_boost\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juampi/Documents/uba/Cuarto%20Cuatrimestre/Organizacion%20de%20Datos/tp2/7506R_TP2_GRUPO23_ENTREGA.ipynb#X51sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m y_pred \u001b[39m=\u001b[39m modelo_xg_boost\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juampi/Documents/uba/Cuarto%20Cuatrimestre/Organizacion%20de%20Datos/tp2/7506R_TP2_GRUPO23_ENTREGA.ipynb#X51sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "vectorizer = TfidfVectorizer(max_features=9000)\n",
    "X = vectorizer.fit_transform(df_preprocesado_copy['review_es'])\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "modelo_xg_boost = XGBClassifier(\n",
    "    # learning_rate=0.001,\n",
    "    n_estimators=500,\n",
    "    # max_depth=5,\n",
    "    # min_child_weight=1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "modelo_xg_boost.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo_xg_boost.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1_score: {f1}')\n",
    "f1_train = f1_score(y_train, modelo_xg_boost.predict(X_train))\n",
    "print(f'F1_score train: {f1_train}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(tabla, annot=True, fmt='d')\n",
    "plt.xlabel('Predicho')\n",
    "plt.ylabel('Real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "vectorizer = TfidfVectorizer(max_features=7000)\n",
    "X = vectorizer.fit_transform(df_preprocesado_copy['review_es'])\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "modelo_xg_boost = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.1,  0.3,  0.5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'learning_rate': list(np.linspace(0.001, 0.1, 10)),\n",
    "        'n_estimators': [ 300, 400, 500, 600 ],\n",
    "        }\n",
    "\n",
    "folds = 5\n",
    "n_iter = 75\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 42)\n",
    "random_search = RandomizedSearchCV(modelo_xg_boost, param_distributions=params, n_iter=n_iter, scoring='f1', n_jobs=-1, cv=skf.split(X_train,y_train), verbose=3, random_state=42 )\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best score:')\n",
    "print(random_search.best_score_ * 2 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_search.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1_score: {f1}')\n",
    "f1_train = f1_score(y_train, random_search.predict(X_train))\n",
    "print(f'F1_score train: {f1_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.8636243735162227\n",
      "F1_score train: 0.9279236007120052\n"
     ]
    }
   ],
   "source": [
    "# colsample_bytree=0.6, gamma=0.1, learning_rate=0.08900000000000001, min_child_weight=10, n_estimators=600, subsample=0.6;, score=0.853\n",
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocesado_copy['review_es'], df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "modelo_xg_boost = Pipeline([\n",
    "  ('tfidf', TfidfVectorizer(max_features=9000)), \n",
    "  ('xgb', XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        colsample_bytree=0.6, \n",
    "        subsample=0.6,\n",
    "        gamma=0.3, \n",
    "        max_depth=5,\n",
    "        learning_rate=0.089, \n",
    "        min_child_weight=10, \n",
    "        n_estimators=700, \n",
    "))])\n",
    "\n",
    "modelo_xg_boost.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo_xg_boost.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1_score: {f1}')\n",
    "f1_train = f1_score(y_train, modelo_xg_boost.predict(X_train))\n",
    "print(f'F1_score train: {f1_train}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicción en los datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv', sep=',')\n",
    "df_test_copia = df_test.copy()\n",
    "df_test_copia['review_es'] = df_test_copia['review_es'].apply(preprocess_text)\n",
    "\n",
    "prediccion = modelo_xg_boost.predict(df_test_copia['review_es'])\n",
    "prediccion = np.where(prediccion == 0, 'negativo', 'positivo')\n",
    "\n",
    "df_entrega = df_test.copy()\n",
    "\n",
    "df_entrega['sentimiento'] = prediccion\n",
    "df_entrega.drop('review_es', axis=1, inplace=True)\n",
    "\n",
    "df_entrega.to_csv('entrega.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.8187729350415244\n",
      "F1_score train: 0.8417005382840822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocesado_copy['review_es'], df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "modelo_random_forest = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=7000)), \n",
    "    ('rfc', RandomForestClassifier(\n",
    "            criterion='entropy',\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            max_depth=20,\n",
    "            min_samples_leaf=50,\n",
    "            n_estimators=1000,\n",
    "    ))])\n",
    "\n",
    "modelo_random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo_random_forest.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1_score: {f1}')\n",
    "f1_train = f1_score(y_train, modelo_random_forest.predict(X_train))\n",
    "print(f'F1_score train: {f1_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 1000)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 1000, 128)         1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 65        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 21:13:40.011933: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-15 21:13:40.014735: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-15 21:13:40.015271: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-15 21:13:40.113433: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-11-15 21:13:40.289713: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-15 21:13:40.290439: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-15 21:13:40.291343: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-15 21:13:40.575435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-15 21:13:40.576486: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-15 21:13:40.576974: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.7700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 21:16:44.401087: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-15 21:16:44.401976: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-15 21:16:44.402541: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 210s 1s/step - loss: 0.4712 - accuracy: 0.7700 - val_loss: 0.3429 - val_accuracy: 0.8530\n",
      "Epoch 2/10\n",
      "190/190 [==============================] - 232s 1s/step - loss: 0.2686 - accuracy: 0.8945 - val_loss: 0.3485 - val_accuracy: 0.8507\n",
      "465/465 [==============================] - 58s 126ms/step - loss: 0.3531 - accuracy: 0.8504\n",
      "Test set\n",
      "  Loss: 0.353\n",
      "  Accuracy: 0.850\n",
      "  1/465 [..............................] - ETA: 7:32"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 21:22:02.769788: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-15 21:22:02.770414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-15 21:22:02.770957: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465/465 [==============================] - 53s 113ms/step\n",
      "Accuracy: 0.8504032258064517\n",
      "Recall: 0.8519913885898815\n",
      "Precision: 0.8490211853043711\n",
      "f1 score: 0.8505036937541974\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "keras.utils.set_random_seed(812)\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "\n",
    "\n",
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocesado_copy['review_es'], df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "max_words = 10000\n",
    "max_len = 1000\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = pad_sequences(sequences,maxlen=max_len)\n",
    "\n",
    "def red_neuronal_recurrente():\n",
    "    inputs = Input(name='inputs', shape=[max_len])\n",
    "    layer = Embedding(max_words, 128, input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    # layer = Dense(256,name='FC1')(layer)\n",
    "    # layer = Activation('relu')(layer)\n",
    "    # layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = tf.keras.Model(inputs=inputs,outputs=layer)\n",
    "    return model\n",
    "\n",
    "model_rnn = red_neuronal_recurrente()\n",
    "model_rnn.summary()\n",
    "model_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_rnn.fit(sequences_matrix, y_train, batch_size=128, epochs=10, \n",
    "            validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "\n",
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = pad_sequences(test_sequences, maxlen=max_len)\n",
    "\n",
    "accr = model_rnn.evaluate(test_sequences_matrix, y_test)\n",
    "\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "\n",
    "prediccion = model_rnn.predict(test_sequences_matrix)\n",
    "prediccion = np.where(prediccion >= 0.5, 1, 0)\n",
    "mostrar_scores(y_test, prediccion)\n",
    "prediccion = np.where(prediccion == 1, 'positivo', 'negativo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediccion_heatmap = np.where(prediccion == 'positivo', 1, 0)\n",
    "\n",
    "tabla = confusion_matrix(y_test, prediccion_heatmap)\n",
    "sns.heatmap(tabla, annot=True, fmt='d')\n",
    "plt.xlabel('Predicho')\n",
    "plt.ylabel('Real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/1085 [..............................] - ETA: 4:56"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 21:23:10.561498: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-15 21:23:10.561955: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-15 21:23:10.562568: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085/1085 [==============================] - 114s 105ms/step\n",
      "Accuracy: 0.9131311385696592\n",
      "Recall: 0.9119399564569726\n",
      "Precision: 0.9149804552770752\n",
      "f1 score: 0.9134576757532281\n"
     ]
    }
   ],
   "source": [
    "train_sequences = tok.texts_to_sequences(X_train)\n",
    "train_sequences_matrix = pad_sequences(train_sequences, maxlen=max_len)\n",
    "prediccion_train = model_rnn.predict(train_sequences_matrix)\n",
    "prediccion_train = np.where(prediccion_train >= 0.5, 1, 0)\n",
    "mostrar_scores(y_train, prediccion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 22:15:33.883538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-15 22:15:33.884783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-15 22:15:33.885307: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-15 22:15:34.065454: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-15 22:15:34.066121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-15 22:15:34.066747: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-11-15 22:15:34.340900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-15 22:15:34.341563: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-15 22:15:34.342222: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085/1085 [==============================] - 553s 509ms/step - loss: 0.4476 - accuracy: 0.7848\n",
      "Epoch 2/10\n",
      "1085/1085 [==============================] - 536s 494ms/step - loss: 0.2515 - accuracy: 0.8988\n",
      "Epoch 3/10\n",
      "1085/1085 [==============================] - 531s 489ms/step - loss: 0.1804 - accuracy: 0.9318\n",
      "Epoch 4/10\n",
      "1085/1085 [==============================] - 533s 491ms/step - loss: 0.1094 - accuracy: 0.9612\n",
      "Epoch 5/10\n",
      "1085/1085 [==============================] - 539s 497ms/step - loss: 0.0599 - accuracy: 0.9803\n",
      "Epoch 6/10\n",
      "1085/1085 [==============================] - 553s 509ms/step - loss: 0.0414 - accuracy: 0.9860\n",
      "Epoch 7/10\n",
      "1085/1085 [==============================] - 540s 498ms/step - loss: 0.0246 - accuracy: 0.9921\n",
      "Epoch 8/10\n",
      "1085/1085 [==============================] - 539s 497ms/step - loss: 0.0200 - accuracy: 0.9933\n",
      "Epoch 9/10\n",
      "1085/1085 [==============================] - 536s 494ms/step - loss: 0.0201 - accuracy: 0.9929\n",
      "Epoch 10/10\n",
      "1085/1085 [==============================] - 540s 498ms/step - loss: 0.0162 - accuracy: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28e436290>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "keras.utils.set_random_seed(812)\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "\n",
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_preprocesado_copy['review_es'], df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "max_len = 1000\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = pad_sequences(sequences,maxlen=max_len)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=10000, output_dim=128),\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.GRU(128),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x=sequences_matrix, y=y_train, epochs=10)\n",
    "\n",
    "# model.evaluate(x=x_test, y=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465/465 [==============================] - 53s 113ms/step\n",
      "Accuracy: 0.8436155913978495\n",
      "Recall: 0.8690796555435952\n",
      "Precision: 0.8266990912581594\n",
      "f1 score: 0.8473597900951131\n"
     ]
    }
   ],
   "source": [
    "test_sequences = tok.texts_to_sequences(x_test)\n",
    "test_sequences_matrix = pad_sequences(test_sequences, maxlen=1000)\n",
    "prediccion = model.predict(test_sequences_matrix)\n",
    "prediccion = np.where(prediccion >= 0.5, 1, 0)\n",
    "mostrar_scores(y_test, prediccion)\n",
    "prediccion = np.where(prediccion == 1, 'positivo', 'negativo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 23:53:15.747490: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-11-15 23:53:15.748132: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-11-15 23:53:15.748825: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085/1085 [==============================] - 126s 115ms/step\n",
      "Accuracy: 0.9976669834960684\n",
      "Recall: 0.999427065429128\n",
      "Precision: 0.9959463317156723\n",
      "f1 score: 0.997683662672653\n"
     ]
    }
   ],
   "source": [
    "train_sequences = tok.texts_to_sequences(x_train)\n",
    "train_sequences_matrix = pad_sequences(train_sequences, maxlen=max_len)\n",
    "prediccion_train = model.predict(train_sequences_matrix)\n",
    "prediccion_train = np.where(prediccion_train >= 0.5, 1, 0)\n",
    "mostrar_scores(y_train, prediccion_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.6661885980638221\n",
      "F1_score train: 0.6690817089299063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocesado_copy['review_es'], df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "modelo_svm = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=14500)), \n",
    "    ('svm', SVC(C=0.1, random_state=42, gamma='auto', kernel='poly', degree=3))\n",
    "    ])\n",
    "\n",
    "modelo_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelo_svm.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1_score: {f1}')\n",
    "f1_train = f1_score(y_train, modelo_svm.predict(X_train))\n",
    "print(f'F1_score train: {f1_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensamble de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review_es</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>críticos mencionado después ver solo oz episod...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pequeña pequeña producciónla técnica filmación...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pensé manera maravillosa pasar tiempo fin sema...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>básicamente familia niño pequeño jake piensa z...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>amor tiempo petter mattei película visualmente...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>pensé película hizo buen trabajo derechano tan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>mala parcela mal diálogo mala actuación direcc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>católica enseñada escuelas primarias parroquia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>voy tener desacuerdo comentario anterior lado ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>nadie espera películas star trek altas artes f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49599 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                          review_es  sentimiento\n",
       "0          0  críticos mencionado después ver solo oz episod...            1\n",
       "1          1  pequeña pequeña producciónla técnica filmación...            1\n",
       "2          2  pensé manera maravillosa pasar tiempo fin sema...            1\n",
       "3          3  básicamente familia niño pequeño jake piensa z...            0\n",
       "4          4  amor tiempo petter mattei película visualmente...            1\n",
       "...      ...                                                ...          ...\n",
       "49995  49995  pensé película hizo buen trabajo derechano tan...            1\n",
       "49996  49996  mala parcela mal diálogo mala actuación direcc...            0\n",
       "49997  49997  católica enseñada escuelas primarias parroquia...            0\n",
       "49998  49998  voy tener desacuerdo comentario anterior lado ...            0\n",
       "49999  49999  nadie espera películas star trek altas artes f...            0\n",
       "\n",
       "[49599 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_preprocesado_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.874260752688172\n",
      "Recall: 0.8969321851453176\n",
      "Precision: 0.8578046583451293\n",
      "f1 score: 0.8769321844372822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "df_preprocesado_copy = df_preprocesado.copy()\n",
    "df_preprocesado_copy['sentimiento'] = df_preprocesado_copy['sentimiento'].map({'negativo': 0, 'positivo': 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocesado_copy['review_es'], df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "\n",
    "estimators = [('xgb', modelo_xg_boost), ('lr', modelo_regresion_logistica), ('mnb', modelo_tfidf)]\n",
    "ensamble = VotingClassifier(estimators=estimators, voting='soft')\n",
    "ensamble.fit(X_train, y_train)\n",
    "\n",
    "prediccion = ensamble.predict(X_test)\n",
    "mostrar_scores(y_test, prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9159538005126876\n",
      "Recall: 0.9333677094075856\n",
      "Precision: 0.902748531530533\n",
      "f1 score: 0.9178028169014084\n"
     ]
    }
   ],
   "source": [
    "prediccion_train = ensamble.predict(X_train)\n",
    "\n",
    "mostrar_scores(y_train, prediccion_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediccion en los datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review_es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60000</td>\n",
       "      <td>La mayor virtud de esta película es su existen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60001</td>\n",
       "      <td>No soy un experto cinéfilo, pero pocas veces m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60002</td>\n",
       "      <td>Si no eres un incondicional del humor estilo T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60003</td>\n",
       "      <td>No sé qué está pasando, si la gente se deja ll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60004</td>\n",
       "      <td>Pero cuando amanece,y me quedo solo,siento en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8594</th>\n",
       "      <td>68594</td>\n",
       "      <td>Buena no, lo siguiente. Por fin un film serio ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8595</th>\n",
       "      <td>68595</td>\n",
       "      <td>Me esperaba mucho, pero que mucho, más.Guión m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8596</th>\n",
       "      <td>68596</td>\n",
       "      <td>De mal cuerpo como sensación al finalizar, de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8597</th>\n",
       "      <td>68597</td>\n",
       "      <td>Los que han añadido comentarios os lo han dich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8598</th>\n",
       "      <td>68598</td>\n",
       "      <td>Fui a ver esta película de cine con entusiasmo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8599 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                          review_es\n",
       "0     60000  La mayor virtud de esta película es su existen...\n",
       "1     60001  No soy un experto cinéfilo, pero pocas veces m...\n",
       "2     60002  Si no eres un incondicional del humor estilo T...\n",
       "3     60003  No sé qué está pasando, si la gente se deja ll...\n",
       "4     60004  Pero cuando amanece,y me quedo solo,siento en ...\n",
       "...     ...                                                ...\n",
       "8594  68594  Buena no, lo siguiente. Por fin un film serio ...\n",
       "8595  68595  Me esperaba mucho, pero que mucho, más.Guión m...\n",
       "8596  68596  De mal cuerpo como sensación al finalizar, de ...\n",
       "8597  68597  Los que han añadido comentarios os lo han dich...\n",
       "8598  68598  Fui a ver esta película de cine con entusiasmo...\n",
       "\n",
       "[8599 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv', sep=',')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copia = df_test.copy()\n",
    "df_test_copia['review_es'] = df_test_copia['review_es'].apply(preprocess_text)\n",
    "\n",
    "train_sequences = tok.texts_to_sequences(df_test_copia['review_es'])\n",
    "train_sequences_matrix = pad_sequences(train_sequences, maxlen=max_len)\n",
    "prediccion_final = model.predict(train_sequences_matrix)\n",
    "prediccion_final = np.where(prediccion_final >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "prediccion_final = np.where(prediccion_final == 0, 'negativo', 'positivo')\n",
    "\n",
    "\n",
    "df_entrega = df_test.copy()\n",
    "\n",
    "df_entrega['sentimiento'] = prediccion_final\n",
    "df_entrega.drop('review_es', axis=1, inplace=True)\n",
    "\n",
    "df_entrega.to_csv('rnr_conv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal Recurrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copia = df.copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_preprocesado_copy['review_es'], df_preprocesado_copy['sentimiento'], test_size=0.3, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_copia['review_es'], df_copia['sentimiento'], test_size=0.3, random_state=42)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, lower = True)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "vocabulario = tokenizer.word_index+1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
